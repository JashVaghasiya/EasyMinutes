{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOew1WvcsOgRFuHgUTecdet",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JashVaghasiya/EasyMinutes-MOM/blob/main/Action_words_Rephraser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers nltk torach numpy pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmaHSDn2UB78",
        "outputId": "8725c80d-e11c-4b62-d195-d86b6c527b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torach (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torach\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svlny_SJYrqP",
        "outputId": "bed40ec4-0099-48a9-b7ca-3580c2b055db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Collecting download\n",
            "  Downloading download-0.3.5-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: en_core_web_sm in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from download) (1.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Installing collected packages: download\n",
            "Successfully installed download-0.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I9rFg9zUOjC",
        "outputId": "c9f70012-4840-4fe5-83ab-876942235253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, T5ForConditionalGeneration, T5Tokenizer\n",
        "import torch\n",
        "import nltk\n",
        "import spacy"
      ],
      "metadata": {
        "id": "I6d-ASmtZhh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT models and tokenizer for action detection\n",
        "folder_path = '/content/drive/My Drive/my_model'\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(folder_path)\n",
        "bert_model = BertForSequenceClassification.from_pretrained(folder_path)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ-YLZnNZhdH",
        "outputId": "7c63775b-effc-4f58-8b8f-df1796f69cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load T5 model and tokenizer for paraphrasing\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "t5_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc0bZc8wZhZ4",
        "outputId": "965a3774-11ef-40ee-ee9e-f9d28ff676a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 512)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK models and corpora\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "nltk.download('maxent_ne_chunker', quiet=True)\n",
        "nltk.download('words', quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0_ZOURPZhW5",
        "outputId": "93dcfbdd-09b5-4a95-f630-a74365e9fda8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split transcript into sentences\n",
        "def split_into_sentences(transcript):\n",
        "    sentences = nltk.tokenize.sent_tokenize(transcript)\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "cSbYtCfVZhPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to rephrase action sentences using T5\n",
        "def rephrase_with_model(sentence):\n",
        "    input_ids = t5_tokenizer.encode(sentence, return_tensors=\"pt\").to(device)\n",
        "    outputs = t5_model.generate(input_ids, max_length=100, num_beams=5, early_stopping=True)\n",
        "    paraphrased_text = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return paraphrased_text"
      ],
      "metadata": {
        "id": "9BEU9lDzZgkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to extract action words (verbs) and create phrases\n",
        "def extract_action_words_and_create_phrases(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    phrases = []\n",
        "\n",
        "    for token in doc:\n",
        "        if token.pos_ == \"VERB\":\n",
        "            # Start with the verb itself\n",
        "            phrase = [token.text]\n",
        "\n",
        "            # Capture adverbial modifiers of the verb (e.g., \"quickly ran\")\n",
        "            adverbs = [child.text for child in token.children if child.dep_ == \"advmod\"]\n",
        "            if adverbs:\n",
        "                phrase = adverbs + phrase\n",
        "\n",
        "            # Look for the verb's direct object, prepositional phrases, or nominal subjects\n",
        "            for child in token.children:\n",
        "                if child.dep_ in [\"dobj\", \"pobj\", \"nsubj\", \"nsubjpass\"]:\n",
        "                    # Include compound nouns or adjectives modifying the noun\n",
        "                    modifiers = [grandchild.text for grandchild in child.children if grandchild.dep_ in [\"compound\", \"amod\"]]\n",
        "                    full_noun = ' '.join(modifiers + [child.text])\n",
        "                    phrase.append(full_noun)\n",
        "                elif child.dep_ == \"prep\":\n",
        "                    # Include the preposition and its object, with modifiers\n",
        "                    prep_phrase = [child.text]\n",
        "                    for grandchild in child.children:\n",
        "                        if grandchild.dep_ == \"pobj\":\n",
        "                            prep_modifiers = [ggc.text for ggc in grandchild.children if ggc.dep_ in [\"compound\", \"amod\"]]\n",
        "                            full_prep_noun = ' '.join(prep_modifiers + [grandchild.text])\n",
        "                            prep_phrase.append(full_prep_noun)\n",
        "                    phrase.append(' '.join(prep_phrase))\n",
        "\n",
        "            # Reconstruct the phrase while preserving the original order as much as possible\n",
        "            phrases.append(' '.join(phrase))\n",
        "\n",
        "    return phrases"
      ],
      "metadata": {
        "id": "s8br_wt2Ztov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to classify, rephrase sentences, and extract action phrases\n",
        "def process_transcript_and_extract_phrases(transcript):\n",
        "    sentences = split_into_sentences(transcript)\n",
        "    action_phrases = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        inputs = bert_tokenizer(sentence, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = bert_model(**inputs)\n",
        "\n",
        "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "        predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
        "\n",
        "        # If the sentence is classified as 'Action'\n",
        "        if predicted_class == 1:\n",
        "            action_words_phrases = extract_action_words_and_create_phrases(sentence)\n",
        "            # rephrased_words = rephrase_with_model(action_words_phrases)\n",
        "            action_phrases.extend(action_words_phrases)\n",
        "\n",
        "    return action_phrases"
      ],
      "metadata": {
        "id": "wgAONeb8ZvXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGvSRdweTjK3",
        "outputId": "ed85c92f-fa5f-4399-959a-333ad5eb3f20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action phrases: ['Make', 'replace this with actual transcript']\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "transcript = \"Your transcript text here. Make sure to replace this with your actual transcript.\"\n",
        "action_phrases = process_transcript_and_extract_phrases(transcript)\n",
        "print(\"Action phrases:\", action_phrases)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 2"
      ],
      "metadata": {
        "id": "hBlpFVeRoCth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, T5Tokenizer, T5ForConditionalGeneration\n",
        "import nltk\n",
        "\n",
        "# Make sure to download necessary NLTK data and spaCy model\n",
        "nltk.download('punkt', quiet=True)\n",
        "# !python -m spacy download en_core_web_sm\n",
        "\n",
        "# Load spaCy for NLP tasks\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load BERT and T5 models and tokenizers\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming 'folder_path' contains the BERT model and tokenizer\n",
        "folder_path = '/content/drive/MyDrive/my_model'  # Update this path\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(folder_path)\n",
        "bert_model = BertForSequenceClassification.from_pretrained(folder_path).to(device)\n",
        "\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\").to(device)\n",
        "\n",
        "def split_into_sentences(transcript):\n",
        "    \"\"\"Split transcript into sentences using NLTK.\"\"\"\n",
        "    return nltk.tokenize.sent_tokenize(transcript)\n",
        "\n",
        "def rephrase_with_model(sentence, model, tokenizer, device):\n",
        "    \"\"\"Rephrase a sentence using the T5 model.\"\"\"\n",
        "    input_ids = tokenizer.encode(sentence, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(input_ids, max_length=100, num_beams=5, early_stopping=True)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def extract_and_rephrase_action_phrases(sentence, nlp, t5_model, t5_tokenizer, device):\n",
        "    \"\"\"Extract action phrases from a sentence and rephrase them for clarity.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    action_phrase = \"\"\n",
        "\n",
        "    for token in doc:\n",
        "        # Check for the verb that indicates an action\n",
        "        if token.pos_ == \"VERB\":\n",
        "            # Construct a basic phrase: Verb + Direct Object\n",
        "            direct_objects = [child for child in token.children if child.dep_ == \"dobj\"]\n",
        "            if direct_objects:\n",
        "                action_phrase = token.text + \" \" + \" \".join([dobj.text for dobj in direct_objects])\n",
        "            else:\n",
        "                # If no direct object, use the verb itself\n",
        "                action_phrase = token.text\n",
        "            break  # Focus on the first action verb found for simplicity\n",
        "\n",
        "    # Rephrase the constructed action phrase for better clarity, if any phrase was constructed\n",
        "    if action_phrase:\n",
        "        # Correcting the model usage with proper input formatting\n",
        "        input_ids = t5_tokenizer.encode(action_phrase, return_tensors=\"pt\").to(device)\n",
        "        outputs = t5_model.generate(input_ids, max_length=50, num_beams=5, early_stopping=True)\n",
        "        rephrased_phrase = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        return rephrased_phrase\n",
        "    else:\n",
        "        return \"\"  # Return an empty string if no action verb was identified or no phrase could be constructed\n",
        "\n",
        "def process_transcript_and_extract_refined_phrases(transcript, bert_model, bert_tokenizer, t5_model, t5_tokenizer, nlp, device):\n",
        "    sentences = split_into_sentences(transcript)\n",
        "    refined_phrases = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        inputs = bert_tokenizer.encode_plus(sentence, return_tensors=\"pt\").to(device)\n",
        "        outputs = bert_model(**inputs)  # Corrected line: inputs are unpacked as a dictionary\n",
        "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "        predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
        "\n",
        "        if predicted_class == 1:  # Action sentence\n",
        "            refined_phrase = extract_and_rephrase_action_phrases(sentence, nlp, t5_model, t5_tokenizer, device)\n",
        "            if refined_phrase:\n",
        "                refined_phrases.append(refined_phrase)\n",
        "\n",
        "    return refined_phrases\n",
        "\n",
        "# Example usage\n",
        "transcript = \"you're likely here because you're searching for a random sentence. Sometimes a random word just isn't enough, and that is where the random sentence generator comes into play. By inputting the desired number, you can make a list of as many random sentences as you want or need. Producing random sentences can be helpful in a number of different ways.\"\n",
        "refined_action_phrases = process_transcript_and_extract_refined_phrases(\n",
        "    transcript, bert_model, bert_tokenizer, t5_model, t5_tokenizer, nlp, device)\n",
        "print(\"Refined Action Phrases:\", refined_action_phrases)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OXDsFjxULV_",
        "outputId": "8e3f2139-ea0e-4dc2-f0ea-f96f7bd2f9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refined Action Phrases: ['in putting number', 'Produc sentences']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YUs_u7OvfTVz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}